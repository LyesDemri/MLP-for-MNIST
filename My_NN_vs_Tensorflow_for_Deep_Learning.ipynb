{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrbrOWzWcpTFhoYnn42DT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LyesDemri/MLP-for-MNIST/blob/main/My_NN_vs_Tensorflow_for_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from files"
      ],
      "metadata": {
        "id": "7PjsiAq9h8Y4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5EGG7H-hioj",
        "outputId": "901419ad-41cd-4e61-ffd8-d998fbf92244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been loaded\n"
          ]
        }
      ],
      "source": [
        "%reset -f\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "#load train file\n",
        "file = open('sample_data/mnist_train_small.csv','r');\n",
        "csvreader = csv.reader(file);\n",
        "X = [0]*20000;\n",
        "label = [0]*20000;\n",
        "k=0;\n",
        "for row in csvreader:\n",
        "  label[k] = row[0];\n",
        "  X[k] = row[1:];\n",
        "  k+=1;\n",
        "X = np.double(np.transpose(np.array(X)))/255;\n",
        "\n",
        "T = np.zeros((10,20000));\n",
        "\n",
        "for i in range(20000):\n",
        "  T[int(label[i]),i] = 1;\n",
        "\n",
        "#load test file\n",
        "file = open('sample_data/mnist_test.csv','r');\n",
        "csvreader = csv.reader(file);\n",
        "X_test = [0]*10000;\n",
        "label_test = [0]*10000;\n",
        "k=0;\n",
        "for row in csvreader:\n",
        "  label_test[k] = row[0];\n",
        "  X_test[k] = row[1:];\n",
        "  k+=1;\n",
        "\n",
        "X_test = np.double(np.transpose(np.array(X_test)))/255;\n",
        "\n",
        "T_test = np.zeros((10,10000));\n",
        "\n",
        "for i in range(10000):\n",
        "  T_test[int(label_test[i]),i] = 1;\n",
        "\n",
        "print('Data has been loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recognize digits with my own code first:"
      ],
      "metadata": {
        "id": "GaS48Ip29VNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate network:\n",
        "#layers = ['ReLU']*9 + ['sigmoid'];\n",
        "layers = ['sigmoid','sigmoid']\n",
        "#layers = ['sigmoid']*10;\n",
        "print(layers)\n",
        "n_layers = len(layers);\n",
        "ILU = 784;  #input layer units\n",
        "HLU = 10;   #hidden layer units\n",
        "OLU = 10;   #output layer units\n",
        "W = [0]*n_layers;\n",
        "b = [0]*n_layers;\n",
        "\n",
        "W[0] = np.random.rand(HLU,ILU)*0.1-0.05;\n",
        "b[0] = np.random.rand(HLU,1)*0.1-0.05;\n",
        "for i in range(1,n_layers-1):\n",
        "  W[i] = np.random.rand(HLU,HLU)*0.1-0.05;\n",
        "  b[i] = np.random.rand(HLU,1)*0.1-0.05;\n",
        "W[n_layers-1] = np.random.rand(OLU,HLU)*0.1-0.05;\n",
        "b[n_layers-1] = np.random.rand(OLU,1)*0.1-0.05;\n",
        "\n",
        "#start training:\n",
        "\n",
        "def logsig(x):\n",
        "  y = np.zeros(np.shape(x));\n",
        "  for i in range(len(x)):\n",
        "    y[i] = 1/(1+np.exp(-x[i]));\n",
        "  return y;\n",
        "\n",
        "def ReLU(x):\n",
        "  y = np.zeros(np.shape(x));\n",
        "  for i in range(len(x)):\n",
        "    y[i] = np.max([0,x[i]]);\n",
        "  return y;\n",
        "def derive(Y,layer_type):\n",
        "  derivative = np.zeros(np.shape(Y));\n",
        "  if layer_type == 'sigmoid':\n",
        "    for i in range(len(Y)):\n",
        "      derivative[i] = Y[i]*(1-Y[i]);\n",
        "  elif layer_type == 'ReLU':\n",
        "    for i in range(len(Y)):\n",
        "      derivative[i] = 1;\n",
        "  return derivative;\n",
        "\n",
        "epochs = 10;\n",
        "errors_list = np.zeros(epochs);\n",
        "for epoch in range(epochs):\n",
        "  for i in range(20000):\n",
        "    #forward:\n",
        "    Y = [0]*(n_layers+1);\n",
        "    Y[0] = X[:,[i]];\n",
        "    for l in range(n_layers):\n",
        "      if layers[l] == 'sigmoid':\n",
        "        Y[l+1] = logsig(W[l]@Y[l] + b[l]);\n",
        "      elif layers[l] == 'ReLU':\n",
        "        Y[l+1] = ReLU(W[l]@Y[l] + b[l]);\n",
        "\n",
        "    dEdb = [0]*n_layers;\n",
        "    dEdW = [0]*n_layers;\n",
        "    d = 2*(Y[-1]-T[:,[i]])/10;\n",
        "    for l in range(n_layers-1,-1,-1):\n",
        "      d = d*derive(Y[l+1],layers[l]);\n",
        "      dEdb[l] = d;\n",
        "      dEdW[l] = d@Y[l].transpose();\n",
        "      d = W[l].transpose()@d;\n",
        "    \n",
        "    for l in range(n_layers):\n",
        "      W[l] = W[l] - 0.1*dEdW[l];\n",
        "      b[l] = b[l] - 0.1*dEdb[l];\n",
        "    \n",
        "  errors = 0;\n",
        "  for i in range(20000):\n",
        "    #forward:\n",
        "    Y = [0]*(n_layers+1);\n",
        "    Y[0] = X[:,[i]];\n",
        "    for l in range(n_layers):\n",
        "      if layers[l] == 'sigmoid':\n",
        "        Y[l+1] = logsig(W[l]@Y[l] + b[l]);\n",
        "      elif layers[l] == 'ReLU':\n",
        "        Y[l+1] = ReLU(W[l]@Y[l] + b[l]);\n",
        "    a = np.argmax(Y[n_layers]);\n",
        "    ca = np.argmax(T[:,[i]]);\n",
        "    if ca!=a:\n",
        "      errors+=1;\n",
        "\n",
        "  errors_list[epoch] = errors*100/20000;\n",
        "  print(\"Epoch \",epoch+1, \": \", 100-errors*100/20000, \"% accuracy\")\n",
        "\n",
        "errors = 0;\n",
        "for i in range(10000):\n",
        "  #forward:\n",
        "  Y = [0]*(n_layers+1);\n",
        "  Y[0] = X_test[:,[i]];\n",
        "  for l in range(n_layers):\n",
        "    if layers[l] == 'sigmoid':\n",
        "      Y[l+1] = logsig(W[l]@Y[l] + b[l]);\n",
        "    elif layers[l] == 'ReLU':\n",
        "      Y[l+1] = ReLU(W[l]@Y[l] + b[l]);\n",
        "  a = np.argmax(Y[n_layers]);\n",
        "  ca = np.argmax(T_test[:,[i]]);\n",
        "  if ca!=a:\n",
        "    errors+=1;\n",
        "errors_on_test = errors *100/10000;\n",
        "print(\"Accuracy on test set: \",100-errors_on_test);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n5DOc0v2i-Z",
        "outputId": "dad70834-bcfa-4177-dd6f-0be4ff80e4fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sigmoid', 'sigmoid']\n",
            "Epoch  1 :  30.22 % accuracy\n",
            "Epoch  2 :  64.545 % accuracy\n",
            "Epoch  3 :  84.75 % accuracy\n",
            "Epoch  4 :  88.615 % accuracy\n",
            "Epoch  5 :  89.57 % accuracy\n",
            "Epoch  6 :  90.245 % accuracy\n",
            "Epoch  7 :  90.615 % accuracy\n",
            "Epoch  8 :  91.02 % accuracy\n",
            "Epoch  9 :  91.37 % accuracy\n",
            "Epoch  10 :  91.645 % accuracy\n",
            "Accuracy on test set:  91.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use Tensorflow"
      ],
      "metadata": {
        "id": "EACA0DbsImkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Input((784,)),\n",
        "    tf.keras.layers.Dense(units = 10, activation = 'sigmoid', kernel_initializer = 'RandomUniform', bias_initializer = 'RandomUniform'),  \n",
        "    tf.keras.layers.Dense(units = 10, activation = 'sigmoid', kernel_initializer = 'RandomUniform', bias_initializer = 'RandomUniform')]);\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(0.1), loss = 'MSE', metrics = 'accuracy')\n",
        "model.fit(X.transpose(),T.transpose(),epochs = 10, batch_size = 1);\n",
        "model.evaluate(X_test.transpose(), T_test.transpose(), batch_size = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fbhpyMf2H_e",
        "outputId": "faa18f45-4c08-400c-9dc4-0b8fd47258cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0893 - accuracy: 0.1760\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0653 - accuracy: 0.4817\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0434 - accuracy: 0.7465\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0297 - accuracy: 0.8637\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0230 - accuracy: 0.8918\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 30s 1ms/step - loss: 0.0198 - accuracy: 0.9015\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0179 - accuracy: 0.9071\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 30s 1ms/step - loss: 0.0167 - accuracy: 0.9117\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0159 - accuracy: 0.9153\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0152 - accuracy: 0.9179\n",
            "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0154 - accuracy: 0.9136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01544282864779234, 0.9136000275611877]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}